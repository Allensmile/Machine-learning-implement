{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "朴素贝叶斯算法是基于贝叶斯定理和特征之间条件独立假设的分类方法。对于给定的训练数据集，首先基于特征条件独立假设学习输入/输出的联合概率分布；然后基于此模型，对给定的输入x，利用贝叶斯定理求出后验概率最大的输出y。朴素贝叶斯算法实现简单，学习和预测的效率都很高，是一种常用的方法。\n",
    "\n",
    "本文考虑当特征是连续情形时，朴素贝叶斯分类方法的原理以及如何从零开始实现贝叶斯分类算法。此时，我们通常有两种处理方式，第一种就是将连续特征离散化(区间化)，这样就转换成了离散情形，完全按照特征离散情形即可完成分类，具体原理可以参见上一篇文章。第二种处理方式就是本文的重点，详情请看下文：\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 1. 朴素贝叶斯算法原理\n",
    "\n",
    "\n",
    "与特征是离散情形时原理类似，只是在计算后验概率时有点不一样，具体计算方法如下：\n",
    "\n",
    "这时，可以假设每个类别中的样本集的每个特征均服从正态分布，通过其样本集计算出均值和方差，也就是得到正态分布的密度函数。有了密度函数，就可以把值代入，算出某一点的密度函数的值。为了阐述的更加清楚，下面我摘取了一个实例，以供大家更好的理解。\n",
    "\n",
    "\n",
    "\n",
    "## 2. 朴素贝叶斯的应用\n",
    "\n",
    "\n",
    "下面是一组人类身体特征的统计资料。\n",
    "\n",
    "    　　性别　　身高（英尺）　体重（磅）　　脚掌（英寸）\n",
    "\n",
    "    　　男 　　　6 　　　　　　180　　　　　12\n",
    "    　　男 　　　5.92　　　　　190　　　　　11\n",
    "    　　男 　　　5.58　　　　　170　　　　　12\n",
    "    　　男 　　　5.92　　　　　165　　　　　10\n",
    "    　　女 　　　5 　　　　　　100　　　　　6\n",
    "    　　女 　　　5.5 　　　　　150　　　　　8\n",
    "    　　女 　　　5.42　　　　　130　　　　　7\n",
    "    　　女 　　　5.75　　　　　150　　　　　9\n",
    "\n",
    "已知某人身高6英尺、体重130磅，脚掌8英寸，请问该人是男是女？\n",
    "\n",
    "根据朴素贝叶斯分类器，计算下面这个式子的值。\n",
    "\n",
    "    P(身高|性别) x P(体重|性别) x P(脚掌|性别) x P(性别)\n",
    "\n",
    "这里的困难在于，由于身高、体重、脚掌都是连续变量，不能采用离散变量的方法计算概率。而且由于样本太少，所以也无法分成区间计算。怎么办？\n",
    "\n",
    "这时，可以假设男性和女性的身高、体重、脚掌都是正态分布，通过样本计算出均值和方差，也就是得到正态分布的密度函数。有了密度函数，就可以把值代入，算出某一点的密度函数的值。\n",
    "\n",
    "比如，男性的身高是均值5.855、方差0.035的正态分布。所以，男性的身高为6英尺的概率的相对值等于1.5789（大于1并没有关系，因为这里是密度函数的值，只用来反映各个值的相对可能性）。\n",
    "\n",
    "从上面的计算结果可以看出，分母都一样，因此，我们只需要比价分子的大小即可。显然，P(不转化|Mx上海)的分子大于P(转化|Mx上海)的分子，因此，这个上海男性用户的预测结果是不转化。这就是贝叶斯分类器的基本方法：在统计资料的基础上，依据某些特征，计算各个类别的概率，从而实现分类。\n",
    "\n",
    "$$ p(height|male) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} e^{-\\frac{(6-\\mu)^2}{2 \\sigma^2}} \\approx 1.5789 $$\n",
    "\n",
    "有了这些数据以后，就可以计算性别的分类了。\n",
    "\n",
    "    　　P(身高=6|男) x P(体重=130|男) x P(脚掌=8|男) x P(男)\n",
    "    　　　　= 6.1984 x e-9\n",
    "\n",
    "    　　P(身高=6|女) x P(体重=130|女) x P(脚掌=8|女) x P(女)\n",
    "    　　　　= 5.3778 x e-4\n",
    "\n",
    "可以看到，女性的概率比男性要高出将近10000倍，所以判断该人为女性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.973333333333\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def shuffle_data(X, y, seed=None):\n",
    "    if seed:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    idx = np.arange(X.shape[0])\n",
    "    np.random.shuffle(idx)\n",
    "\n",
    "    return X[idx], y[idx]\n",
    "\n",
    "\n",
    "# 正规化数据集 X\n",
    "def normalize(X, axis=-1, p=2):\n",
    "    lp_norm = np.atleast_1d(np.linalg.norm(X, p, axis))\n",
    "    lp_norm[lp_norm == 0] = 1\n",
    "    return X / np.expand_dims(lp_norm, axis)\n",
    "\n",
    "\n",
    "# 标准化数据集 X\n",
    "def standardize(X):\n",
    "    X_std = np.zeros(X.shape)\n",
    "    mean = X.mean(axis=0)\n",
    "    std = X.std(axis=0)\n",
    "    \n",
    "    # 做除法运算时请永远记住分母不能等于0的情形\n",
    "    # X_std = (X - X.mean(axis=0)) / X.std(axis=0) \n",
    "    for col in range(np.shape(X)[1]):\n",
    "        if std[col]:\n",
    "            X_std[:, col] = (X_std[:, col] - mean[col]) / std[col]\n",
    "    return X_std\n",
    "\n",
    "\n",
    "# 划分数据集为训练集和测试集\n",
    "def train_test_split(X, y, test_size=0.2, shuffle=True, seed=None):\n",
    "    if shuffle:\n",
    "        X, y = shuffle_data(X, y, seed)\n",
    "\n",
    "    n_train_samples = int(X.shape[0] * (1-test_size))\n",
    "    x_train, x_test = X[:n_train_samples], X[n_train_samples:]\n",
    "    y_train, y_test = y[:n_train_samples], y[n_train_samples:]\n",
    "\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "\n",
    "def accuracy(y, y_pred):\n",
    "    y = y.reshape(y.shape[0], -1)\n",
    "    y_pred = y_pred.reshape(y_pred.shape[0], -1)\n",
    "    return np.sum(y == y_pred)/len(y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class NaiveBayes():\n",
    "    \"\"\"朴素贝叶斯分类模型. \"\"\"\n",
    "    def __init__(self):\n",
    "        self.classes = None\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        # 存储高斯分布的参数(均值, 方差), 因为预测的时候需要, 模型训练的过程中其实就是计算出\n",
    "        # 所有高斯分布(因为朴素贝叶斯模型假设每个类别的样本集每个特征都服从高斯分布, 固有多个\n",
    "        # 高斯分布)的参数\n",
    "        self.parameters = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.classes = np.unique(y)\n",
    "        # 计算每一个类别每个特征的均值和方差\n",
    "        for i in range(len(self.classes)):\n",
    "            c = self.classes[i]\n",
    "            # 选出该类别的数据集\n",
    "            x_where_c = X[np.where(y == c)]\n",
    "            # 计算该类别数据集的均值和方差\n",
    "            self.parameters.append([])\n",
    "            for j in range(len(x_where_c[0, :])):\n",
    "                col = x_where_c[:, j]\n",
    "                parameters = {}\n",
    "                parameters[\"mean\"] = col.mean()\n",
    "                parameters[\"var\"] = col.var()\n",
    "                self.parameters[i].append(parameters)\n",
    "\n",
    "    # 计算高斯分布密度函数的值\n",
    "    def calculate_gaussian_probability(self, mean, var, x):\n",
    "        coeff = (1.0 / (math.sqrt((2.0 * math.pi) * var)))\n",
    "        exponent = math.exp(-(math.pow(x - mean, 2) / (2 * var)))\n",
    "        return coeff * exponent\n",
    "\n",
    "    # 计算先验概率 \n",
    "    def calculate_priori_probability(self, c):\n",
    "        x_where_c = self.X[np.where(self.y == c)]\n",
    "        n_samples_for_c = x_where_c.shape[0]\n",
    "        n_samples = self.X.shape[0]\n",
    "        return n_samples_for_c / n_samples\n",
    "\n",
    "    # Classify using Bayes Rule, P(Y|X) = P(X|Y)*P(Y)/P(X)\n",
    "    # P(X|Y) - Probability. Gaussian distribution (given by calculate_probability)\n",
    "    # P(Y) - Prior (given by calculate_prior)\n",
    "    # P(X) - Scales the posterior to the range 0 - 1 (ignored)\n",
    "    # Classify the sample as the class that results in the largest P(Y|X)\n",
    "    # (posterior)\n",
    "    def classify(self, sample):\n",
    "        posteriors = []\n",
    "        \n",
    "        # 遍历所有类别\n",
    "        for i in range(len(self.classes)):\n",
    "            c = self.classes[i]\n",
    "            prior = self.calculate_priori_probability(c)\n",
    "            posterior = np.log(prior)\n",
    "            \n",
    "            # probability = P(Y)*P(x1|Y)*P(x2|Y)*...*P(xN|Y)\n",
    "            # 遍历所有特征 \n",
    "            for j, params in enumerate(self.parameters[i]):\n",
    "                # 取出第i个类别第j个特征的均值和方差\n",
    "                mean = params[\"mean\"]\n",
    "                var = params[\"var\"]\n",
    "                # 取出预测样本的第j个特征\n",
    "                sample_feature = sample[j]\n",
    "                # 按照高斯分布的密度函数计算密度值\n",
    "                prob = self.calculate_gaussian_probability(mean, var, sample_feature)\n",
    "                # 朴素贝叶斯模型假设特征之间条件独立，即P(x1,x2,x3|Y) = P(x1|Y)*P(x2|Y)*P(x3|Y), \n",
    "                # 并且用取对数的方法将累乘转成累加的形式\n",
    "                posterior += np.log(prob)\n",
    "            \n",
    "            posteriors.append(posterior)\n",
    "        \n",
    "        # 对概率进行排序\n",
    "        index_of_max = np.argmax(posteriors)\n",
    "        max_value = posteriors[index_of_max]\n",
    "\n",
    "        return self.classes[index_of_max]\n",
    "\n",
    "    # 对数据集进行类别预测\n",
    "    def predict(self, X):\n",
    "        y_pred = []\n",
    "        for sample in X:\n",
    "            y = self.classify(sample)\n",
    "            y_pred.append(y)\n",
    "        return np.array(y_pred)\n",
    "\n",
    "\n",
    "def main():\n",
    "    data = datasets.load_iris()\n",
    "    X = normalize(data.data)\n",
    "    y = data.target\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
    "\n",
    "    clf = NaiveBayes()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = np.array(clf.predict(X_test))\n",
    "\n",
    "    accu = accuracy(y_test, y_pred)\n",
    "\n",
    "    print (\"Accuracy:\", accu)\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考文献：\n",
    "http://www.ruanyifeng.com/blog/2013/12/naive_bayes_classifier.html\n",
    "\n",
    "李航《统计学习方法》"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
